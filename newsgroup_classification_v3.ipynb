{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# 20 Newsgroups Classification - Hierarchical Attention Network\n",
        "## Experiment 3: Complete Implementation with Report Data Collection\n",
        "\n",
        "---\n",
        "\n",
        "### Architecture (as per problem specification):\n",
        "1. **Contextual Encoder (Bi-LSTM)** - extracts word-level features\n",
        "2. **Word-Level Filtering Attention** - self-attention to identify important words\n",
        "3. **Sentence Representation** - aggregates word features via learned pooling\n",
        "4. **Document-Level Cross-Attention** - filtered words as queries, sentences as keys/values\n",
        "5. **Classification Layer** - predicts newsgroup label\n",
        "\n",
        "### Report Deliverables Data Collection:\n",
        "- (ii) Baseline comparisons with metrics and charts\n",
        "- (iii) Attention distribution visualizations\n",
        "- (iv) Per-class error analysis\n",
        "- (v) Attention influence analysis (quantitative + qualitative)\n",
        "- (vii) Failure mode analysis for two attention stages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio -q\n",
        "!pip install scikit-learn nltk matplotlib seaborn tqdm pandas numpy gensim -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter, defaultdict\n",
        "import re, json, os, tarfile, textwrap\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.utils import Bunch\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import gensim.downloader as api\n",
        "\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TARGET_NAMES = [\n",
        "    'alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc',\n",
        "    'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x',\n",
        "    'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball',\n",
        "    'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med',\n",
        "    'sci.space', 'soc.religion.christian', 'talk.politics.guns',\n",
        "    'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc'\n",
        "]\n",
        "\n",
        "def load_newsgroups_from_folder(folder_path, remove=()):\n",
        "    data, target = [], []\n",
        "    for label_idx, category in enumerate(TARGET_NAMES):\n",
        "        category_path = os.path.join(folder_path, category)\n",
        "        if os.path.exists(category_path):\n",
        "            for filename in os.listdir(category_path):\n",
        "                filepath = os.path.join(category_path, filename)\n",
        "                try:\n",
        "                    with open(filepath, 'r', encoding='latin-1') as f:\n",
        "                        text = f.read()\n",
        "                        if 'headers' in remove:\n",
        "                            lines = text.split('\\n')\n",
        "                            for i, line in enumerate(lines):\n",
        "                                if line.strip() == '':\n",
        "                                    text = '\\n'.join(lines[i+1:])\n",
        "                                    break\n",
        "                        if 'footers' in remove:\n",
        "                            lines = text.split('\\n')\n",
        "                            for i in range(len(lines)-1, -1, -1):\n",
        "                                if lines[i].strip() == '--':\n",
        "                                    text = '\\n'.join(lines[:i])\n",
        "                                    break\n",
        "                        if 'quotes' in remove:\n",
        "                            lines = text.split('\\n')\n",
        "                            lines = [l for l in lines if not l.strip().startswith('>')]\n",
        "                            text = '\\n'.join(lines)\n",
        "                        data.append(text)\n",
        "                        target.append(label_idx)\n",
        "                except: continue\n",
        "    return Bunch(data=data, target=np.array(target), target_names=TARGET_NAMES)\n",
        "\n",
        "try:\n",
        "    newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "    newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
        "    print(\"Dataset loaded via sklearn.\")\n",
        "except Exception as e:\n",
        "    print(f\"Direct download failed: {e}\\nUsing manual download...\")\n",
        "    data_home = os.path.expanduser('~/scikit_learn_data')\n",
        "    twenty_home = os.path.join(data_home, '20news_home')\n",
        "    os.makedirs(twenty_home, exist_ok=True)\n",
        "    archive_path = os.path.join(twenty_home, '20news-bydate.tar.gz')\n",
        "    if not os.path.exists(archive_path):\n",
        "        !wget --user-agent=\"Mozilla/5.0\" -O \"{archive_path}\" \"http://qwone.com/~jason/20Newsgroups/20news-bydate.tar.gz\"\n",
        "    train_path = os.path.join(twenty_home, '20news-bydate-train')\n",
        "    if not os.path.exists(train_path):\n",
        "        with tarfile.open(archive_path, 'r:gz') as tar:\n",
        "            tar.extractall(path=twenty_home)\n",
        "    newsgroups_train = load_newsgroups_from_folder(os.path.join(twenty_home, '20news-bydate-train'), remove=('headers', 'footers', 'quotes'))\n",
        "    newsgroups_test = load_newsgroups_from_folder(os.path.join(twenty_home, '20news-bydate-test'), remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "print(f\"Training samples: {len(newsgroups_train.data)}\")\n",
        "print(f\"Test samples: {len(newsgroups_test.data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Class Distribution Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_counts = Counter(newsgroups_train.target)\n",
        "test_counts = Counter(newsgroups_test.target)\n",
        "\n",
        "class_data = [{'ID': i, 'Category': name, 'Train': train_counts[i], 'Test': test_counts[i], \n",
        "               'Total': train_counts[i] + test_counts[i], \n",
        "               'Train%': round(train_counts[i] / len(newsgroups_train.data) * 100, 2)}\n",
        "              for i, name in enumerate(TARGET_NAMES)]\n",
        "\n",
        "class_df = pd.DataFrame(class_data)\n",
        "print(\"CLASS DISTRIBUTION\\n\" + \"=\"*80)\n",
        "print(class_df.to_string(index=False))\n",
        "class_df.to_csv('class_distribution.csv', index=False)\n",
        "\n",
        "train_counts_list = [train_counts[i] for i in range(20)]\n",
        "imbalance_ratio = max(train_counts_list) / min(train_counts_list)\n",
        "print(f\"\\nImbalance Ratio: {imbalance_ratio:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "x = np.arange(20)\n",
        "width = 0.35\n",
        "ax.bar(x - width/2, [train_counts[i] for i in range(20)], width, label='Train', color='steelblue')\n",
        "ax.bar(x + width/2, [test_counts[i] for i in range(20)], width, label='Test', color='darkorange')\n",
        "ax.set_xlabel('Category', fontsize=12)\n",
        "ax.set_ylabel('Number of Documents', fontsize=12)\n",
        "ax.set_title('20 Newsgroups - Class Distribution', fontsize=14)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(TARGET_NAMES, rotation=45, ha='right', fontsize=9)\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('class_distribution.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"SAMPLE DOCUMENTS\\n\" + \"=\"*80)\n",
        "for class_idx in [0, 1, 7, 11, 15]:\n",
        "    indices = np.where(newsgroups_train.target == class_idx)[0]\n",
        "    text = ' '.join(newsgroups_train.data[indices[0]].split())[:300]\n",
        "    print(f\"\\n[{class_idx}] {TARGET_NAMES[class_idx]}\\n\" + \"-\"*40)\n",
        "    print(textwrap.fill(text + \"...\", width=80))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TextPreprocessor:\n",
        "    def __init__(self, min_word_freq=2, max_vocab_size=50000, max_sent_len=50, max_doc_sents=30):\n",
        "        self.min_word_freq = min_word_freq\n",
        "        self.max_vocab_size = max_vocab_size\n",
        "        self.max_sent_len = max_sent_len\n",
        "        self.max_doc_sents = max_doc_sents\n",
        "        self.word2idx = {'<PAD>': 0, '<UNK>': 1}\n",
        "        self.idx2word = {0: '<PAD>', 1: '<UNK>'}\n",
        "        self.vocab_size = 2\n",
        "    \n",
        "    def clean_text(self, text):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'\\S+@\\S+', '', text)\n",
        "        text = re.sub(r'http\\S+|www\\S+', '', text)\n",
        "        text = re.sub(r'[^a-zA-Z0-9\\s\\.\\!\\?]', ' ', text)\n",
        "        return re.sub(r'\\s+', ' ', text).strip()\n",
        "    \n",
        "    def tokenize_document(self, text):\n",
        "        text = self.clean_text(text)\n",
        "        sentences = sent_tokenize(text)\n",
        "        doc_tokens = []\n",
        "        for sent in sentences[:self.max_doc_sents]:\n",
        "            words = [w for w in word_tokenize(sent) if w.isalpha() and len(w) > 1]\n",
        "            if words: doc_tokens.append(words[:self.max_sent_len])\n",
        "        return doc_tokens\n",
        "    \n",
        "    def build_vocab(self, documents):\n",
        "        word_freq = Counter()\n",
        "        for doc in tqdm(documents, desc=\"Building vocabulary\"):\n",
        "            for sent in self.tokenize_document(doc):\n",
        "                word_freq.update(sent)\n",
        "        for word in [w for w, c in word_freq.most_common(self.max_vocab_size) if c >= self.min_word_freq]:\n",
        "            self.word2idx[word] = self.vocab_size\n",
        "            self.idx2word[self.vocab_size] = word\n",
        "            self.vocab_size += 1\n",
        "        print(f\"Vocabulary size: {self.vocab_size}\")\n",
        "        return self\n",
        "    \n",
        "    def encode_document(self, text):\n",
        "        encoded_doc = [[self.word2idx.get(w, 1) for w in sent] for sent in self.tokenize_document(text)]\n",
        "        encoded_doc = [s for s in encoded_doc if s]\n",
        "        return encoded_doc if encoded_doc else [[1]]\n",
        "\n",
        "preprocessor = TextPreprocessor(min_word_freq=2, max_vocab_size=50000, max_sent_len=50, max_doc_sents=30)\n",
        "preprocessor.build_vocab(newsgroups_train.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Load GloVe Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Loading GloVe embeddings...\")\n",
        "glove_vectors = api.load('glove-wiki-gigaword-300')\n",
        "print(f\"Loaded {len(glove_vectors)} word vectors\")\n",
        "\n",
        "EMBED_DIM = 300\n",
        "embedding_matrix = np.zeros((preprocessor.vocab_size, EMBED_DIM))\n",
        "found_count = 0\n",
        "for word, idx in tqdm(preprocessor.word2idx.items(), desc=\"Building embedding matrix\"):\n",
        "    if word in glove_vectors:\n",
        "        embedding_matrix[idx] = glove_vectors[word]\n",
        "        found_count += 1\n",
        "    else:\n",
        "        embedding_matrix[idx] = np.random.normal(0, 0.1, EMBED_DIM)\n",
        "embedding_matrix[0] = np.zeros(EMBED_DIM)\n",
        "embedding_matrix = torch.FloatTensor(embedding_matrix)\n",
        "print(f\"Embedding coverage: {found_count}/{preprocessor.vocab_size} ({found_count/preprocessor.vocab_size*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NewsGroupDataset(Dataset):\n",
        "    def __init__(self, documents, labels, preprocessor):\n",
        "        self.documents, self.labels, self.preprocessor = documents, labels, preprocessor\n",
        "    def __len__(self): return len(self.documents)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.preprocessor.encode_document(self.documents[idx]), self.labels[idx], idx\n",
        "\n",
        "def collate_fn(batch):\n",
        "    docs, labels, indices = zip(*batch)\n",
        "    doc_lengths = [len(doc) for doc in docs]\n",
        "    max_doc_len = max(doc_lengths)\n",
        "    sent_lengths = [[len(sent) for sent in doc] + [1]*(max_doc_len-len(doc)) for doc in docs]\n",
        "    max_sent_len = max(max(len(sent) for sent in doc) for doc in docs)\n",
        "    padded_docs = [[sent + [0]*(max_sent_len-len(sent)) for sent in doc] + [[0]*max_sent_len]*(max_doc_len-len(doc)) for doc in docs]\n",
        "    return (torch.LongTensor(padded_docs), torch.LongTensor(labels), \n",
        "            torch.LongTensor(doc_lengths), torch.LongTensor(sent_lengths), torch.LongTensor(indices))\n",
        "\n",
        "train_dataset = NewsGroupDataset(newsgroups_train.data, newsgroups_train.target, preprocessor)\n",
        "test_dataset = NewsGroupDataset(newsgroups_test.data, newsgroups_test.target, preprocessor)\n",
        "\n",
        "train_size = int(0.9 * len(train_dataset))\n",
        "train_subset, val_subset = torch.utils.data.random_split(train_dataset, [train_size, len(train_dataset)-train_size], generator=torch.Generator().manual_seed(SEED))\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "print(f\"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}, Test batches: {len(test_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class WordLevelEncoder(nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_dim, num_layers=2, dropout=0.4):\n",
        "        super().__init__()\n",
        "        vocab_size, embed_dim = embedding_matrix.shape\n",
        "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, bidirectional=True, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
        "        self.residual_proj = nn.Linear(embed_dim, hidden_dim * 2)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm = nn.LayerNorm(hidden_dim * 2)\n",
        "        self.hidden_dim = hidden_dim * 2\n",
        "    \n",
        "    def forward(self, x, lengths):\n",
        "        embedded = self.dropout(self.embedding(x))\n",
        "        residual = self.residual_proj(embedded)\n",
        "        packed = pack_padded_sequence(embedded, lengths.cpu().clamp(min=1), batch_first=True, enforce_sorted=False)\n",
        "        outputs, _ = self.lstm(packed)\n",
        "        outputs, _ = pad_packed_sequence(outputs, batch_first=True)\n",
        "        if outputs.size(1) < residual.size(1):\n",
        "            outputs = torch.cat([outputs, torch.zeros(outputs.size(0), residual.size(1)-outputs.size(1), outputs.size(2), device=outputs.device)], dim=1)\n",
        "        return self.layer_norm(outputs + residual)\n",
        "\n",
        "class WordLevelAttention(nn.Module):\n",
        "    def __init__(self, hidden_dim, attention_dim, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.attention = nn.Sequential(nn.Linear(hidden_dim, attention_dim), nn.Tanh(), nn.Dropout(dropout))\n",
        "        self.context = nn.Linear(attention_dim, 1, bias=False)\n",
        "    \n",
        "    def forward(self, hidden_states, mask=None):\n",
        "        attn_scores = self.context(self.attention(hidden_states)).squeeze(-1)\n",
        "        if mask is not None: attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
        "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
        "        return torch.bmm(attn_weights.unsqueeze(1), hidden_states).squeeze(1), attn_weights\n",
        "\n",
        "class SentenceEncoder(nn.Module):\n",
        "    def __init__(self, embedding_matrix, word_hidden_dim, attention_dim, num_layers=2, dropout=0.4):\n",
        "        super().__init__()\n",
        "        self.word_encoder = WordLevelEncoder(embedding_matrix, word_hidden_dim, num_layers, dropout)\n",
        "        self.word_attention = WordLevelAttention(word_hidden_dim * 2, attention_dim, dropout)\n",
        "        self.hidden_dim = word_hidden_dim * 2\n",
        "    \n",
        "    def forward(self, sentences, sent_lengths):\n",
        "        word_hidden = self.word_encoder(sentences, sent_lengths)\n",
        "        mask = torch.arange(sentences.size(1), device=sentences.device).unsqueeze(0) < sent_lengths.unsqueeze(1)\n",
        "        sent_repr, word_attn = self.word_attention(word_hidden, mask)\n",
        "        return sent_repr, word_attn, word_hidden\n",
        "\n",
        "class DocumentCrossAttention(nn.Module):\n",
        "    def __init__(self, hidden_dim, num_heads=8, dropout=0.4):\n",
        "        super().__init__()\n",
        "        self.hidden_dim, self.num_heads, self.head_dim = hidden_dim, num_heads, hidden_dim // num_heads\n",
        "        self.query_proj = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.key_proj = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.value_proj = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.output_proj = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, word_queries, sentence_kv, sent_mask=None):\n",
        "        batch_size, num_queries, num_sents = word_queries.size(0), word_queries.size(1), sentence_kv.size(1)\n",
        "        Q = self.query_proj(word_queries).view(batch_size, num_queries, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        K = self.key_proj(sentence_kv).view(batch_size, num_sents, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.value_proj(sentence_kv).view(batch_size, num_sents, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(self.head_dim)\n",
        "        if sent_mask is not None: attn_scores = attn_scores.masked_fill(sent_mask.unsqueeze(1).unsqueeze(2) == 0, -1e9)\n",
        "        attn_weights = self.dropout(F.softmax(attn_scores, dim=-1))\n",
        "        attended = torch.matmul(attn_weights, V).transpose(1, 2).contiguous().view(batch_size, num_queries, self.hidden_dim)\n",
        "        return self.output_proj(attended).mean(dim=1), attn_weights.mean(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HierarchicalAttentionNetwork(nn.Module):\n",
        "    def __init__(self, embedding_matrix, word_hidden_dim, sent_hidden_dim, attention_dim, num_classes, num_heads=8, num_layers=2, dropout=0.4, top_k_words=15):\n",
        "        super().__init__()\n",
        "        self.top_k_words = top_k_words\n",
        "        self.sentence_encoder = SentenceEncoder(embedding_matrix, word_hidden_dim, attention_dim, num_layers, dropout)\n",
        "        word_repr_dim = word_hidden_dim * 2\n",
        "        self.sent_lstm = nn.LSTM(word_repr_dim, sent_hidden_dim, num_layers=num_layers, bidirectional=True, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
        "        sent_repr_dim = sent_hidden_dim * 2\n",
        "        self.sent_residual_proj = nn.Linear(word_repr_dim, sent_repr_dim)\n",
        "        self.sent_layer_norm = nn.LayerNorm(sent_repr_dim)\n",
        "        self.sent_attention = WordLevelAttention(sent_repr_dim, attention_dim, dropout)\n",
        "        self.cross_attention = DocumentCrossAttention(sent_repr_dim, num_heads=num_heads, dropout=dropout)\n",
        "        self.word_proj = nn.Linear(word_repr_dim, sent_repr_dim)\n",
        "        self.gate = nn.Sequential(nn.Linear(sent_repr_dim * 2, sent_repr_dim), nn.Sigmoid())\n",
        "        self.classifier = nn.Sequential(nn.Linear(sent_repr_dim, sent_repr_dim // 2), nn.ReLU(), nn.Dropout(dropout), nn.Linear(sent_repr_dim // 2, num_classes))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, docs, doc_lengths, sent_lengths, return_attention=False):\n",
        "        batch_size, max_sents, max_words = docs.size()\n",
        "        sent_reprs, all_word_attns, all_word_hiddens = [], [], []\n",
        "        for i in range(max_sents):\n",
        "            sent_repr, word_attn, word_hidden = self.sentence_encoder(docs[:, i, :], sent_lengths[:, i])\n",
        "            sent_reprs.append(sent_repr); all_word_attns.append(word_attn); all_word_hiddens.append(word_hidden)\n",
        "        sent_reprs = torch.stack(sent_reprs, dim=1)\n",
        "        all_word_attns = torch.stack(all_word_attns, dim=1)\n",
        "        all_word_hiddens = torch.stack(all_word_hiddens, dim=1)\n",
        "        \n",
        "        residual = self.sent_residual_proj(sent_reprs)\n",
        "        packed_sents = pack_padded_sequence(sent_reprs, doc_lengths.cpu().clamp(min=1), batch_first=True, enforce_sorted=False)\n",
        "        sent_outputs, _ = self.sent_lstm(packed_sents)\n",
        "        sent_outputs, _ = pad_packed_sequence(sent_outputs, batch_first=True)\n",
        "        if sent_outputs.size(1) < max_sents:\n",
        "            sent_outputs = torch.cat([sent_outputs, torch.zeros(batch_size, max_sents-sent_outputs.size(1), sent_outputs.size(2), device=sent_outputs.device)], dim=1)\n",
        "        sent_outputs = self.sent_layer_norm(sent_outputs + residual)\n",
        "        \n",
        "        sent_mask = torch.arange(max_sents, device=docs.device).unsqueeze(0) < doc_lengths.unsqueeze(1)\n",
        "        sent_attn_output, sent_attn_weights = self.sent_attention(sent_outputs, sent_mask)\n",
        "        \n",
        "        k = min(self.top_k_words, max_words)\n",
        "        _, top_word_indices = torch.topk(all_word_attns, k, dim=-1)\n",
        "        filtered_words = torch.gather(all_word_hiddens.view(batch_size*max_sents, max_words, -1), dim=1, index=top_word_indices.view(batch_size*max_sents, k).unsqueeze(-1).expand(-1, -1, all_word_hiddens.size(-1))).view(batch_size, max_sents*k, -1)\n",
        "        filtered_words_proj = self.dropout(self.word_proj(filtered_words))\n",
        "        cross_attn_output, cross_attn_weights = self.cross_attention(filtered_words_proj, sent_outputs, sent_mask)\n",
        "        \n",
        "        gate_weights = self.gate(torch.cat([sent_attn_output, cross_attn_output], dim=-1))\n",
        "        doc_repr = gate_weights * cross_attn_output + (1 - gate_weights) * sent_attn_output\n",
        "        logits = self.classifier(doc_repr)\n",
        "        \n",
        "        if return_attention:\n",
        "            return logits, {'word_attention': all_word_attns, 'sentence_attention': sent_attn_weights, 'cross_attention': cross_attn_weights, 'top_word_indices': top_word_indices, 'gate_weights': gate_weights}\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "WORD_HIDDEN_DIM, SENT_HIDDEN_DIM, ATTENTION_DIM = 256, 256, 128\n",
        "NUM_CLASSES, NUM_HEADS, NUM_LSTM_LAYERS, DROPOUT, TOP_K_WORDS = 20, 8, 2, 0.4, 15\n",
        "\n",
        "model = HierarchicalAttentionNetwork(embedding_matrix, WORD_HIDDEN_DIM, SENT_HIDDEN_DIM, ATTENTION_DIM, NUM_CLASSES, NUM_HEADS, NUM_LSTM_LAYERS, DROPOUT, TOP_K_WORDS).to(device)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_weights = compute_class_weight('balanced', classes=np.unique(newsgroups_train.target), y=newsgroups_train.target)\n",
        "class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
        "\n",
        "LEARNING_RATE, WEIGHT_DECAY, LABEL_SMOOTHING = 0.001, 1e-4, 0.1\n",
        "NUM_EPOCHS, PATIENCE, GRAD_CLIP = 20, 5, 1.0\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor, label_smoothing=LABEL_SMOOTHING)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS, eta_min=1e-6)\n",
        "\n",
        "def train_epoch(model, loader, criterion, optimizer, device, grad_clip):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    for docs, labels, doc_lengths, sent_lengths, _ in tqdm(loader, desc=\"Training\"):\n",
        "        docs, labels = docs.to(device), labels.to(device)\n",
        "        doc_lengths, sent_lengths = doc_lengths.to(device), sent_lengths.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(docs, doc_lengths, sent_lengths)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        correct += (logits.argmax(dim=1) == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    return total_loss / len(loader), correct / total\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss, all_preds, all_labels, all_indices = 0, [], [], []\n",
        "    with torch.no_grad():\n",
        "        for docs, labels, doc_lengths, sent_lengths, indices in tqdm(loader, desc=\"Evaluating\"):\n",
        "            docs, labels = docs.to(device), labels.to(device)\n",
        "            doc_lengths, sent_lengths = doc_lengths.to(device), sent_lengths.to(device)\n",
        "            logits = model(docs, doc_lengths, sent_lengths)\n",
        "            total_loss += criterion(logits, labels).item()\n",
        "            all_preds.extend(logits.argmax(dim=1).cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_indices.extend(indices.cpu().numpy())\n",
        "    all_preds, all_labels = np.array(all_preds), np.array(all_labels)\n",
        "    return {'loss': total_loss/len(loader), 'accuracy': accuracy_score(all_labels, all_preds),\n",
        "            'precision': precision_score(all_labels, all_preds, average='weighted', zero_division=0),\n",
        "            'recall': recall_score(all_labels, all_preds, average='weighted', zero_division=0),\n",
        "            'f1': f1_score(all_labels, all_preds, average='weighted', zero_division=0),\n",
        "            'macro_f1': f1_score(all_labels, all_preds, average='macro', zero_division=0)}, all_preds, all_labels, all_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'val_f1': [], 'lr': []}\n",
        "best_val_f1, early_stop_counter = 0, 0\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, GRAD_CLIP)\n",
        "    val_metrics, _, _, _ = evaluate(model, val_loader, criterion, device)\n",
        "    scheduler.step()\n",
        "    \n",
        "    history['train_loss'].append(train_loss); history['train_acc'].append(train_acc)\n",
        "    history['val_loss'].append(val_metrics['loss']); history['val_acc'].append(val_metrics['accuracy'])\n",
        "    history['val_f1'].append(val_metrics['f1']); history['lr'].append(optimizer.param_groups[0]['lr'])\n",
        "    \n",
        "    print(f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | Val Loss: {val_metrics['loss']:.4f}, Acc: {val_metrics['accuracy']:.4f}, F1: {val_metrics['f1']:.4f}\")\n",
        "    \n",
        "    if val_metrics['f1'] > best_val_f1:\n",
        "        best_val_f1, early_stop_counter = val_metrics['f1'], 0\n",
        "        torch.save(model.state_dict(), 'best_model.pt')\n",
        "        print(\"✓ Saved best model!\")\n",
        "    else:\n",
        "        early_stop_counter += 1\n",
        "        if early_stop_counter >= PATIENCE:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "print(f\"\\nBest Validation F1: {best_val_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "axes[0,0].plot(history['train_loss'], label='Train'); axes[0,0].plot(history['val_loss'], label='Val')\n",
        "axes[0,0].set_title('Loss'); axes[0,0].legend()\n",
        "axes[0,1].plot(history['train_acc'], label='Train'); axes[0,1].plot(history['val_acc'], label='Val')\n",
        "axes[0,1].set_title('Accuracy'); axes[0,1].legend()\n",
        "axes[1,0].plot(history['val_f1']); axes[1,0].set_title('Validation F1')\n",
        "axes[1,1].plot(history['lr']); axes[1,1].set_title('Learning Rate')\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_history.png', dpi=150)\n",
        "plt.show()\n",
        "pd.DataFrame(history).to_csv('training_history.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Baseline Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tfidf = TfidfVectorizer(max_features=10000, stop_words='english')\n",
        "X_train_tfidf = tfidf.fit_transform(newsgroups_train.data)\n",
        "X_test_tfidf = tfidf.transform(newsgroups_test.data)\n",
        "y_train, y_test = newsgroups_train.target, newsgroups_test.target\n",
        "\n",
        "baselines = {}\n",
        "for name, clf in [('Logistic Regression', LogisticRegression(max_iter=1000, class_weight='balanced')),\n",
        "                  ('Naive Bayes', MultinomialNB()),\n",
        "                  ('Linear SVM', LinearSVC(max_iter=2000, class_weight='balanced'))]:\n",
        "    print(f\"Training {name}...\")\n",
        "    clf.fit(X_train_tfidf, y_train)\n",
        "    preds = clf.predict(X_test_tfidf)\n",
        "    baselines[name] = {'accuracy': accuracy_score(y_test, preds), 'precision': precision_score(y_test, preds, average='weighted'),\n",
        "                       'recall': recall_score(y_test, preds, average='weighted'), 'f1': f1_score(y_test, preds, average='weighted'),\n",
        "                       'macro_f1': f1_score(y_test, preds, average='macro')}\n",
        "    print(f\"  Accuracy: {baselines[name]['accuracy']:.4f}, F1: {baselines[name]['f1']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Test Evaluation & Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('best_model.pt'))\n",
        "test_metrics, test_preds, test_labels, test_indices = evaluate(model, test_loader, criterion, device)\n",
        "baselines['HAN (Ours)'] = {k: test_metrics[k] for k in ['accuracy', 'precision', 'recall', 'f1', 'macro_f1']}\n",
        "\n",
        "print(\"\\nTEST RESULTS\\n\" + \"=\"*60)\n",
        "print(f\"Accuracy: {test_metrics['accuracy']:.4f}, Precision: {test_metrics['precision']:.4f}\")\n",
        "print(f\"Recall: {test_metrics['recall']:.4f}, F1: {test_metrics['f1']:.4f}, Macro F1: {test_metrics['macro_f1']:.4f}\")\n",
        "\n",
        "comparison_df = pd.DataFrame([{'Model': k, **{m.capitalize(): f\"{v[m]:.4f}\" for m in ['accuracy','precision','recall','f1']}} for k,v in baselines.items()])\n",
        "print(\"\\nMODEL COMPARISON\\n\", comparison_df.to_string(index=False))\n",
        "comparison_df.to_csv('model_comparison.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "models = list(baselines.keys())\n",
        "x = np.arange(len(models))\n",
        "for i, (metric, color) in enumerate(zip(['accuracy','precision','recall','f1'], ['#2ecc71','#3498db','#9b59b6','#e74c3c'])):\n",
        "    axes[0].bar(x + i*0.2, [baselines[m][metric] for m in models], 0.2, label=metric.capitalize(), color=color)\n",
        "axes[0].set_xticks(x + 0.3); axes[0].set_xticklabels(models, rotation=15, ha='right')\n",
        "axes[0].legend(); axes[0].set_title('Model Comparison')\n",
        "\n",
        "colors = ['steelblue' if m != 'HAN (Ours)' else 'darkgreen' for m in models]\n",
        "bars = axes[1].bar(models, [baselines[m]['f1'] for m in models], color=colors)\n",
        "for bar, val in zip(bars, [baselines[m]['f1'] for m in models]):\n",
        "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, f'{val:.3f}', ha='center')\n",
        "axes[1].set_title('F1 Score Comparison')\n",
        "plt.tight_layout()\n",
        "plt.savefig('model_comparison.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Error Analysis (Deliverable iv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm = confusion_matrix(test_labels, test_preds)\n",
        "plt.figure(figsize=(16, 14))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=TARGET_NAMES, yticklabels=TARGET_NAMES)\n",
        "plt.xlabel('Predicted'); plt.ylabel('True'); plt.title('Confusion Matrix')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrix.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(test_labels, test_preds, target_names=TARGET_NAMES))\n",
        "\n",
        "report_dict = classification_report(test_labels, test_preds, target_names=TARGET_NAMES, output_dict=True)\n",
        "per_class_df = pd.DataFrame([{'ID': i, 'Category': name, 'Precision': report_dict[name]['precision'],\n",
        "                              'Recall': report_dict[name]['recall'], 'F1-Score': report_dict[name]['f1-score'],\n",
        "                              'Support': report_dict[name]['support']} for i, name in enumerate(TARGET_NAMES)])\n",
        "per_class_df = per_class_df.sort_values('F1-Score')\n",
        "per_class_df.to_csv('per_class_metrics.csv', index=False)\n",
        "print(\"\\nPer-Class Metrics (sorted by F1):\")\n",
        "print(per_class_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "colors = plt.cm.RdYlGn(per_class_df['F1-Score'].values)\n",
        "bars = ax.barh(per_class_df['Category'], per_class_df['F1-Score'], color=colors)\n",
        "ax.axvline(x=test_metrics['f1'], color='red', linestyle='--', label=f\"Overall F1: {test_metrics['f1']:.3f}\")\n",
        "ax.set_xlabel('F1 Score'); ax.set_title('Per-Class F1 Scores'); ax.legend()\n",
        "for bar, val in zip(bars, per_class_df['F1-Score']):\n",
        "    ax.text(val + 0.01, bar.get_y() + bar.get_height()/2, f'{val:.3f}', va='center')\n",
        "plt.tight_layout()\n",
        "plt.savefig('per_class_f1.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "confused_pairs = [{'True': TARGET_NAMES[i], 'Predicted': TARGET_NAMES[j], 'Count': cm[i,j], 'Pct': cm_norm[i,j]*100}\n",
        "                  for i in range(20) for j in range(20) if i != j and cm[i,j] > 0]\n",
        "confused_df = pd.DataFrame(confused_pairs).sort_values('Count', ascending=False)\n",
        "print(\"\\nTop 15 Misclassifications:\")\n",
        "print(confused_df.head(15).to_string(index=False))\n",
        "confused_df.to_csv('confusion_analysis.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Attention Analysis (Deliverable iii & v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attention_stats = {'word_entropy': [], 'word_max': [], 'sent_entropy': [], 'sent_max': [], 'gate_mean': [], 'correct': [], 'true_label': [], 'pred_label': []}\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for docs, labels, doc_lengths, sent_lengths, _ in tqdm(test_loader, desc=\"Collecting attention\"):\n",
        "        docs, doc_lengths, sent_lengths = docs.to(device), doc_lengths.to(device), sent_lengths.to(device)\n",
        "        logits, attn = model(docs, doc_lengths, sent_lengths, return_attention=True)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        word_attn, sent_attn, gate = attn['word_attention'].cpu().numpy(), attn['sentence_attention'].cpu().numpy(), attn['gate_weights'].cpu().numpy()\n",
        "        for i in range(docs.size(0)):\n",
        "            attention_stats['word_entropy'].append(np.mean(-np.sum(word_attn[i] * np.log(word_attn[i] + 1e-10), axis=-1)))\n",
        "            attention_stats['word_max'].append(np.max(word_attn[i]))\n",
        "            attention_stats['sent_entropy'].append(-np.sum(sent_attn[i] * np.log(sent_attn[i] + 1e-10)))\n",
        "            attention_stats['sent_max'].append(np.max(sent_attn[i]))\n",
        "            attention_stats['gate_mean'].append(np.mean(gate[i]))\n",
        "            attention_stats['correct'].append(int(preds[i].item() == labels[i].item()))\n",
        "            attention_stats['true_label'].append(labels[i].item())\n",
        "            attention_stats['pred_label'].append(preds[i].item())\n",
        "\n",
        "attention_df = pd.DataFrame(attention_stats)\n",
        "attention_df.to_csv('attention_statistics.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "correct_df = attention_df[attention_df['correct'] == 1]\n",
        "incorrect_df = attention_df[attention_df['correct'] == 0]\n",
        "\n",
        "print(\"\\nATTENTION INFLUENCE ANALYSIS (Deliverable v)\\n\" + \"=\"*60)\n",
        "print(f\"Correct: {len(correct_df)}, Incorrect: {len(incorrect_df)}\")\n",
        "for metric in ['word_entropy', 'word_max', 'sent_entropy', 'gate_mean']:\n",
        "    print(f\"\\n{metric}:\")\n",
        "    print(f\"  Correct: {correct_df[metric].mean():.4f} ± {correct_df[metric].std():.4f}\")\n",
        "    print(f\"  Incorrect: {incorrect_df[metric].mean():.4f} ± {incorrect_df[metric].std():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "for ax, metric, title in zip(axes.flat, ['word_entropy', 'sent_entropy', 'gate_mean', 'word_max'],\n",
        "                              ['Word Attention Entropy', 'Sentence Attention Entropy', 'Gate Weight', 'Max Word Attention']):\n",
        "    ax.hist(correct_df[metric], bins=30, alpha=0.7, label='Correct', color='green')\n",
        "    ax.hist(incorrect_df[metric], bins=30, alpha=0.7, label='Incorrect', color='red')\n",
        "    ax.set_xlabel(title); ax.set_ylabel('Frequency'); ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('attention_statistics.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_attention_for_sample(model, doc, label, preprocessor, device):\n",
        "    model.eval()\n",
        "    encoded_doc = preprocessor.encode_document(doc)\n",
        "    doc_length, sent_lengths = len(encoded_doc), [len(s) for s in encoded_doc]\n",
        "    max_sent_len = max(sent_lengths)\n",
        "    padded_doc = [s + [0]*(max_sent_len-len(s)) for s in encoded_doc]\n",
        "    with torch.no_grad():\n",
        "        logits, attn = model(torch.LongTensor([padded_doc]).to(device), torch.LongTensor([doc_length]).to(device),\n",
        "                             torch.LongTensor([sent_lengths]).to(device), return_attention=True)\n",
        "    return {'tokens': preprocessor.tokenize_document(doc), 'word_attention': attn['word_attention'][0].cpu().numpy(),\n",
        "            'sentence_attention': attn['sentence_attention'][0].cpu().numpy(), 'prediction': logits.argmax(dim=1).item(),\n",
        "            'true_label': label, 'correct': logits.argmax(dim=1).item() == label}\n",
        "\n",
        "for sample_type, idx in [('CORRECT', np.where(test_preds == test_labels)[0][0]), ('INCORRECT', np.where(test_preds != test_labels)[0][0])]:\n",
        "    attn_data = get_attention_for_sample(model, newsgroups_test.data[idx], newsgroups_test.target[idx], preprocessor, device)\n",
        "    print(f\"\\n{sample_type}: True={TARGET_NAMES[attn_data['true_label']]}, Pred={TARGET_NAMES[attn_data['prediction']]}\")\n",
        "    for si, (toks, wa) in enumerate(zip(attn_data['tokens'][:3], attn_data['word_attention'][:3])):\n",
        "        if toks:\n",
        "            top_idx = np.argsort(wa[:len(toks)])[-3:][::-1]\n",
        "            print(f\"  Sent {si}: {', '.join([f'{toks[i]}({wa[i]:.3f})' for i in top_idx if i < len(toks)])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Failure Mode Analysis (Deliverable vii)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "incorrect_idx = np.where(test_preds != test_labels)[0]\n",
        "failure_data = []\n",
        "for idx in tqdm(incorrect_idx[:100], desc=\"Analyzing failures\"):\n",
        "    attn_data = get_attention_for_sample(model, newsgroups_test.data[idx], newsgroups_test.target[idx], preprocessor, device)\n",
        "    wa, sa = attn_data['word_attention'], attn_data['sentence_attention']\n",
        "    failure_data.append({'idx': idx, 'true_class': TARGET_NAMES[attn_data['true_label']], 'pred_class': TARGET_NAMES[attn_data['prediction']],\n",
        "                         'word_max_mean': np.mean(np.max(wa, axis=-1)), 'word_entropy': np.mean(-np.sum(wa * np.log(wa + 1e-10), axis=-1)),\n",
        "                         'sent_max': np.max(sa), 'sent_entropy': -np.sum(sa * np.log(sa + 1e-10)), 'num_sents': len(attn_data['tokens'])})\n",
        "failure_df = pd.DataFrame(failure_data)\n",
        "failure_df.to_csv('failure_analysis.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nFAILURE MODES IDENTIFIED\\n\" + \"=\"*60)\n",
        "modes = [\n",
        "    (\"1. WORD OVER-CONCENTRATION\", failure_df['word_max_mean'] > 0.5, \"Attention focuses on single words, losing context\"),\n",
        "    (\"2. DIFFUSE SENTENCE ATTENTION\", failure_df['sent_entropy'] > failure_df['sent_entropy'].median(), \"Cross-attention spreads too evenly\"),\n",
        "    (\"3. SHORT DOCUMENTS\", failure_df['num_sents'] < 3, \"Insufficient hierarchical context\"),\n",
        "    (\"4. HIGH WORD ENTROPY\", failure_df['word_entropy'] > failure_df['word_entropy'].median(), \"Word attention too uncertain\")\n",
        "]\n",
        "for name, mask, desc in modes:\n",
        "    count = mask.sum()\n",
        "    print(f\"\\n{name}: {count} cases ({count/len(failure_df)*100:.1f}%)\")\n",
        "    print(f\"   {desc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "for ax, col, title, thresh in zip(axes.flat, ['word_max_mean', 'sent_entropy', 'num_sents', 'word_entropy'],\n",
        "                                   ['Word Over-Concentration', 'Sentence Entropy', 'Document Length', 'Word Entropy'],\n",
        "                                   [0.5, failure_df['sent_entropy'].median(), 3, failure_df['word_entropy'].median()]):\n",
        "    ax.hist(failure_df[col], bins=20, color='red', alpha=0.7, edgecolor='black')\n",
        "    ax.axvline(x=thresh, color='black', linestyle='--', label=f'Threshold: {thresh:.2f}')\n",
        "    ax.set_xlabel(title); ax.set_ylabel('Frequency'); ax.legend()\n",
        "plt.suptitle('Failure Mode Analysis', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.savefig('failure_modes.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "failure_report = \"\"\"\n",
        "FAILURE MODE ANALYSIS REPORT\n",
        "============================\n",
        "\n",
        "FAILURE MODE 1: Word-Level Over-Concentration\n",
        "- Problem: Attention focuses too heavily on single words\n",
        "- Impact: Important contextual words filtered out before cross-attention\n",
        "- Fix: Temperature scaling, attention smoothing, increase top_k\n",
        "\n",
        "FAILURE MODE 2: Diffuse Sentence Attention\n",
        "- Problem: Cross-attention spreads weight too evenly\n",
        "- Impact: Model fails to identify relevant sentences\n",
        "- Fix: Sentence positional encoding, sparse attention\n",
        "\n",
        "FAILURE MODE 3: Information Loss at Word Filtering\n",
        "- Problem: Important words filtered at word-level stage\n",
        "- Impact: Cannot contribute to cross-attention queries\n",
        "- Fix: Soft filtering, residual connections, auxiliary supervision\n",
        "\n",
        "FAILURE MODE 4: Encoder Representation Collapse\n",
        "- Problem: Similar representations for different words\n",
        "- Impact: Attention selection becomes arbitrary\n",
        "- Fix: Pre-trained BERT, contrastive loss, orthogonality regularization\n",
        "\"\"\"\n",
        "print(failure_report)\n",
        "with open('failure_mode_report.txt', 'w') as f:\n",
        "    f.write(failure_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Save Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary = {'experiment': 'HAN v3', 'train_samples': len(newsgroups_train.data), 'test_samples': len(newsgroups_test.data),\n",
        "           'vocab_size': preprocessor.vocab_size, 'embed_dim': EMBED_DIM, 'word_hidden_dim': WORD_HIDDEN_DIM,\n",
        "           'sent_hidden_dim': SENT_HIDDEN_DIM, 'num_heads': NUM_HEADS, 'dropout': DROPOUT, 'top_k_words': TOP_K_WORDS,\n",
        "           'epochs_trained': len(history['train_loss']), 'best_val_f1': best_val_f1,\n",
        "           'test_accuracy': test_metrics['accuracy'], 'test_f1': test_metrics['f1'], 'test_macro_f1': test_metrics['macro_f1'],\n",
        "           'total_params': total_params}\n",
        "\n",
        "pd.DataFrame([summary]).to_csv('experiment_summary.csv', index=False)\n",
        "with open('experiment_summary.json', 'w') as f: json.dump(summary, f, indent=2)\n",
        "\n",
        "print(\"\\nEXPERIMENT SUMMARY\\n\" + \"=\"*60)\n",
        "for k, v in summary.items(): print(f\"  {k}: {v}\")\n",
        "\n",
        "print(\"\\n\\nSAVED FILES:\")\n",
        "for f in ['best_model.pt', 'class_distribution.csv', 'class_distribution.png', 'training_history.csv', 'training_history.png',\n",
        "          'model_comparison.csv', 'model_comparison.png', 'confusion_matrix.png', 'per_class_metrics.csv', 'per_class_f1.png',\n",
        "          'confusion_analysis.csv', 'attention_statistics.csv', 'attention_statistics.png', 'failure_analysis.csv',\n",
        "          'failure_modes.png', 'failure_mode_report.txt', 'experiment_summary.csv', 'experiment_summary.json']:\n",
        "    print(f\"  - {f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Save to Google Drive\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    import shutil\n",
        "    dest = '/content/drive/MyDrive/20_Newsgroups_HAN_v3'\n",
        "    os.makedirs(dest, exist_ok=True)\n",
        "    for f in os.listdir('.'):\n",
        "        if f.endswith(('.pt', '.csv', '.png', '.json', '.txt')):\n",
        "            shutil.copy(f, dest)\n",
        "    print(f\"Files saved to {dest}\")\n",
        "except: print(\"Not in Colab - files saved locally\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {"display_name": "Python 3", "name": "python3"},
    "accelerator": "GPU",
    "colab": {"provenance": [], "gpuType": "T4"}
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
